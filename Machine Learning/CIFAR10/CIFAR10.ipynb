{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "353ae4a3",
   "metadata": {},
   "source": [
    "This project deals with classifying the CIFAR-10 dataset using convolutional neural networks (CNNs).\n",
    "\n",
    "I explored using CNNs with both max pooling and different strides, but I decided to focus on max pooling in my final model. I used several different kernel sizes in my convolutional layers with the intention of picking up image features of varying scale. The data was then flattened and run through two dense layers before the output layer. I also employed batch normalization and dropout layers after every convolutional and dense layer. I explored different dropout rates and found the rate that gave the best model predictions. Finally, I explored varying the number of convolutional layers and decided that two layers for each kernel size gave optimal predictions. Models using dropout more sparingly and using L2 normalization were also created, but the model that gave the best predictions is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bb1fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.utils import to_categorical as to_cat\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4179e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "(train, train_labels), (test, test_labels) = cifar10.load_data()\n",
    "\n",
    "#format data\n",
    "train = train.astype('float32') / 255\n",
    "test = test.astype('float32') / 255\n",
    "train_labels = to_cat(train_labels)\n",
    "test_labels = to_cat(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69c3c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define early stopping criteria\n",
    "es = EarlyStopping(monitor='val_loss', mode='min',\\\n",
    "                   patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2153de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define cnn model\n",
    "cnn_maxpool = models.Sequential()\n",
    "\n",
    "cnn_maxpool.add(layers.Conv2D(32, (3, 3), activation = 'relu',\\\n",
    "                              padding = 'same', input_shape = (32, 32, 3)))\n",
    "cnn_maxpool.add(layers.BatchNormalization())\n",
    "cnn_maxpool.add(layers.Dropout(0.3))\n",
    "\n",
    "cnn_maxpool.add(layers.Conv2D(32, (3, 3), activation = 'relu',\\\n",
    "                              padding = 'same'))\n",
    "cnn_maxpool.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_maxpool.add(layers.BatchNormalization())\n",
    "cnn_maxpool.add(layers.Dropout(0.3))\n",
    "\n",
    "cnn_maxpool.add(layers.Conv2D(64, (5, 5), padding = 'same',\\\n",
    "                              activation = 'relu'))\n",
    "cnn_maxpool.add(layers.BatchNormalization())\n",
    "cnn_maxpool.add(layers.Dropout(0.3))\n",
    "\n",
    "cnn_maxpool.add(layers.Conv2D(64, (5, 5), padding = 'same',\\\n",
    "                              activation = 'relu'))\n",
    "cnn_maxpool.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_maxpool.add(layers.BatchNormalization())\n",
    "cnn_maxpool.add(layers.Dropout(0.3))\n",
    "\n",
    "cnn_maxpool.add(layers.Conv2D(128, (7, 7), padding = 'same',\\\n",
    "                              activation = 'relu'))\n",
    "cnn_maxpool.add(layers.BatchNormalization())\n",
    "cnn_maxpool.add(layers.Dropout(0.3))\n",
    "\n",
    "cnn_maxpool.add(layers.Conv2D(128, (7, 7), padding = 'same',\\\n",
    "                              activation = 'relu'))\n",
    "cnn_maxpool.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_maxpool.add(layers.BatchNormalization())\n",
    "cnn_maxpool.add(layers.Dropout(0.3))\n",
    "\n",
    "cnn_maxpool.add(layers.Flatten())\n",
    "\n",
    "cnn_maxpool.add(layers.Dense(128, activation = 'relu'))\n",
    "cnn_maxpool.add(layers.BatchNormalization())\n",
    "cnn_maxpool.add(layers.Dropout(0.3))\n",
    "\n",
    "cnn_maxpool.add(layers.Dense(64, activation = 'relu'))\n",
    "cnn_maxpool.add(layers.BatchNormalization())\n",
    "cnn_maxpool.add(layers.Dropout(0.3))\n",
    "                \n",
    "cnn_maxpool.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29db7ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model\n",
    "cnn_maxpool.compile(\n",
    "    optimizer = 'rmsprop',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87326f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit model\n",
    "cnn_maxpool.fit(train,\n",
    "                train_labels,\n",
    "                epochs = 50,\n",
    "                batch_size = 64,\n",
    "                validation_split = 0.2,\n",
    "                callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c5216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions and write to file\n",
    "preds = cnn_maxpool.predict(test)\n",
    "preds = np.array([np.argmax(x) for x in preds])\n",
    "ids = np.array(range(10000)) + 1\n",
    "out = pd.DataFrame(np.transpose([ids, preds]),\\\n",
    "                  columns = ['id', 'class'])\n",
    "out.to_csv('predictions_maxpool.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Cody Minns"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "title": "STAA Homework 3"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
